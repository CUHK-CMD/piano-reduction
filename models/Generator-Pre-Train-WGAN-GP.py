#!/usr/bin/env python
# coding: utf-8

# # use Python 3 (ipykernel)

# In[1]:


import tensorflow as tf
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.callbacks import ModelCheckpoint
import numpy as np


# In[2]:


#Parameters
K_bar = 1 #Number of tracks generated by the generator
num_sequential_bars = 1 #For discriminator
num_tracks = 1 #For discriminator
batch_size = 64
skip_connections = True
random_vector_size=16
discriminator_extra_steps = 3


# In[3]:


# load trained autoencoder
from tensorflow.keras.models import load_model
trained_autoencoder = load_model('NEWpiano_encoder-loss0.03.hdf5', custom_objects={'LeakyReLU': LeakyReLU})
trained_autoencoder.summary()


# In[4]:


# GAN generator structure

# pretrained encoder
pretrained_encoder_input = trained_autoencoder.input
pretrained_encoder_output = trained_autoencoder.get_layer(index=11).output
pretrained_encoder = tf.keras.Model(pretrained_encoder_input,pretrained_encoder_output,name='pretrained_encoder')
#Thomas: try to freeze the encoder training first, to stabilize training 
pretrained_encoder.trainable = True #TRUE NOW

# generator
generator_input = tf.keras.Input((1,1,16+random_vector_size), name='gen_input')
x = tf.keras.layers.Conv2DTranspose(1024,(2,1),(2,1),activation="relu")(generator_input)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Conv2DTranspose(256,(2,1),(2,1),activation="relu")(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Conv2DTranspose(256,(2,1),(2,1),activation="relu")(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Conv2DTranspose(256,(2,1),(2,1),activation="relu")(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Conv2DTranspose(128,(2,1),(2,1),activation="relu")(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Conv2DTranspose(128,(3,1),(3,1),activation="relu")(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Conv2DTranspose(64,(1,7),(1,7),activation="relu")(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Conv2DTranspose(K_bar,(1,12),(1,12),activation="sigmoid")(x)
generator_output = tf.keras.layers.BatchNormalization()(x)
generator = tf.keras.Model(generator_input,generator_output,name='generator')


#random vector
random_vector_input = tf.keras.Input((random_vector_size))

#concatenate
random_and_latent = tf.keras.layers.concatenate([pretrained_encoder.output, random_vector_input],axis=-1)
random_and_latent = tf.keras.layers.Reshape((1,1,16+random_vector_size))(random_and_latent)

#generator
gan = generator(random_and_latent)

gan_generator = tf.keras.Model([pretrained_encoder_input, random_vector_input],gan,name='gan_generator')


# In[5]:


# discriminator: 1: Fake, 0: Real
discriminator_paired_input1 = tf.keras.Input((num_sequential_bars,96,84,num_tracks))
discriminator_paired_input2 = tf.keras.Input((num_sequential_bars,96,84,num_tracks))
x = tf.keras.layers.concatenate([discriminator_paired_input1,discriminator_paired_input2])
x = tf.keras.layers.Conv3D(128,(1,1,1),(1,1,1),activation=LeakyReLU())(x)
x = tf.keras.layers.Conv3D(128,(1,1,1),(1,1,1),activation=LeakyReLU())(x)
x = tf.keras.layers.Conv3D(128,(1,1,12),(1,1,12),activation=LeakyReLU())(x)
x = tf.keras.layers.Conv3D(128,(1,1,7),(1,1,7),activation=LeakyReLU())(x)
x = tf.keras.layers.Conv3D(128,(1,2,1),(1,2,1),activation=LeakyReLU())(x)
x = tf.keras.layers.Conv3D(128,(1,2,1),(1,2,1),activation=LeakyReLU())(x)
x = tf.keras.layers.Conv3D(256,(1,4,1),(1,4,1),activation=LeakyReLU())(x)
x = tf.keras.layers.Conv3D(512,(1,3,1),(1,2,1),activation=LeakyReLU())(x)
x = tf.keras.layers.Flatten()(x)
#Thomas: CHange this to linear (from sigmoid)
discriminator_output = tf.keras.layers.Dense(1, activation='linear')(x)
discriminator_paired = tf.keras.Model([discriminator_paired_input1,discriminator_paired_input2],discriminator_output)


# In[6]:


gan_generator.summary()


# In[7]:


discriminator_paired.summary()


# In[8]:


#piano to orchestra
#Thomas: WGAN-GP https://keras.io/examples/generative/wgan_gp/
class GAN_p2o(tf.keras.Model):
    def __init__(self, discriminator, generator,discriminator_extra_steps,gp_weight=10):
        super(GAN_p2o, self).__init__()
        self.discriminator = discriminator
        self.generator = generator
        self.d_steps = discriminator_extra_steps
        self.gp_weight = gp_weight
        self.generator_loss_tracker = tf.keras.metrics.Mean(name="generator_loss")
        self.discriminator_loss_tracker = tf.keras.metrics.Mean(name="discriminator_loss")
        
    @property
    def metrics(self):
        return [self.generator_loss_tracker, self.discriminator_loss_tracker]
    
    def compile(self, discriminator_optimizer, generator_optimizer, d_loss_fn,g_loss_fn):
        super(GAN_p2o, self).compile()
        self.d_optimizer = discriminator_optimizer
        self.g_optimizer = generator_optimizer
        self.d_loss_fn = d_loss_fn
        self.g_loss_fn = g_loss_fn
        
    def gradient_penalty(self, batch_size, real_piano, real_orchestra,fake_orchestra):
        """ Calculates the gradient penalty.

        This loss is calculated on an interpolated image
        and added to the discriminator loss.
        """
        # Get the interpolated image
        alpha = tf.random.normal([batch_size, 1,1,1,1], 0.0, 1.0)
        diff = fake_orchestra - real_orchestra
        interpolated = real_orchestra + alpha * diff

        with tf.GradientTape() as gp_tape:
            gp_tape.watch(interpolated)
            # 1. Get the discriminator output for this interpolated image.
            pred = self.discriminator([real_piano,interpolated], training=True)

        # 2. Calculate the gradients w.r.t to this interpolated image.
        grads = gp_tape.gradient(pred, [interpolated])[0]
        # 3. Calculate the norm of the gradients.
        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))
        gp = tf.reduce_mean((norm - 1.0) ** 2)
        return gp
        
    def train_step(self, data):
        # input Assumption (not verified yet)
        # piano_x: Shape(96,84,1), a bar of paried piano score
        # (Removed) random_vector: Shape(16), a random vector sampled from Normal(0,1)
        # orchestra_y: Shape(96,84,1), a bar of paired orchestra score
        piano_x, orchestra_y = data
        batch_size = tf.shape(piano_x)[0]
        #train discriminator
        for i in range(self.d_steps):
            random_vector = tf.random.normal(shape=(batch_size, random_vector_size))
            with tf.GradientTape() as tape:
                fake_orchestra = self.generator([piano_x,random_vector])
                fake_orchestra = tf.reshape(fake_orchestra, (-1,1,96,84,1))
                real_orchestra = tf.reshape(orchestra_y, (-1,1,96,84,1))
                piano_input = tf.reshape(piano_x, (-1,1,96,84,1)) 
                fake_prediction = self.discriminator([piano_input,fake_orchestra])
                real_prediction = self.discriminator([piano_input,real_orchestra])
                d_cost = self.d_loss_fn(real_prediction,fake_prediction)
                gp = self.gradient_penalty(batch_size,piano_input,real_orchestra,fake_orchestra)
                d_loss = d_cost + gp * self.gp_weight
            d_gradient= tape.gradient(d_loss,self.discriminator.trainable_weights)
            self.d_optimizer.apply_gradients(zip(d_gradient, self.discriminator.trainable_weights))
            
        #train generator
        random_vector = tf.random.normal(shape=(batch_size, random_vector_size))
        with tf.GradientTape() as tape:
            fake_orchestra = self.generator([piano_x,random_vector])
            fake_orchestra = tf.reshape(fake_orchestra, (-1,1,96,84,1))
            piano_input = tf.reshape(piano_x, (-1,1,96,84,1)) 
            discriminator_pred = self.discriminator([piano_input,fake_orchestra])
            g_loss = self.g_loss_fn(discriminator_pred)
        #calculate generator gradient
        gen_gradient = tape.gradient(g_loss, self.generator.trainable_weights)
        #update generator weight        
        self.g_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_weights))
        
        #Loss
        self.generator_loss_tracker.update_state(g_loss)
        self.discriminator_loss_tracker.update_state(d_loss)
        return{"generator_loss": self.generator_loss_tracker.result(),
               "discriminator_loss": self.discriminator_loss_tracker.result()}
    


# In[9]:


test = GAN_p2o(discriminator_paired, gan_generator,discriminator_extra_steps)


# In[10]:


def discriminator_loss(real_img, fake_img):
    #basically real = -1, fake = 1 here, using lienar function with reduce_mean to avoid optimizing to a certain value
    real_loss = tf.reduce_mean(real_img)
    fake_loss = tf.reduce_mean(fake_img)
    return fake_loss - real_loss


def generator_loss(fake_img):
    return -tf.reduce_mean(fake_img)


test.compile(tf.keras.optimizers.Adam(learning_rate=0.0003), #discriminator
             tf.keras.optimizers.Adam(learning_rate=0.0003), #generator
             discriminator_loss, #ORiginal : CrossEntropy
             generator_loss
            )


# # TRAINING STAGE
# 1. Train two autoencoders on orchestra and piano samples respectively.
# 2. Pre-train Generators with pretrain_discriminator, on orchestra and piano repsectively (pix2pix approach)
# 3. Train on unpaired with Cycle-GAN approach #we update G once every five updates of D and apply batch normalization only to G

# In[11]:


import pickle 
with open("paired.pickle","rb") as f:
    paired_data = pickle.load(f)
print(len(paired_data))


# In[12]:


orchestra=[]
piano=[]
for piece in paired_data:
    for segment in piece['o']:
        for bar in segment:
            if bar is not None:
                orchestra.append(bar)
    for segment in piece['p']:
        for bar in segment:
            if bar is not None:
                piano.append(bar)
orchestra=np.array(orchestra).astype('float32')
piano=np.array(piano).astype('float32')
assert(orchestra.shape == piano.shape)


# In[13]:


assert(piano.shape == orchestra.shape)
dataset = tf.data.Dataset.from_tensor_slices((piano, orchestra))
dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)


# In[31]:


history = test.fit(dataset, epochs=2,verbose=2)


# In[30]:


import pickle
with open("train_history.pickle","wb") as f:
    pickle.dump(history.history,f)
    
with open("train_history.pickle","rb") as f:
    data = pickle.load(f)
print(data)


# In[ ]:


# DEBUG


# In[ ]:


# test


# In[22]:


#some visualization
from miditoolkit.pianoroll import parser as pr_parser
from miditoolkit.midi import parser as mid_parser
from miditoolkit.midi import containers as ct
def write_midi(notes,path='out.mid',tick_per_beat=24):
    out = mid_parser.MidiFile()
    out.ticks_per_beat = tick_per_beat
    out.instruments = [ct.Instrument(program=0,is_drum=False,name='post-processed piano')]
    for note in notes:
        assert(note.velocity)
        out.instruments[0].notes.append(ct.Note(start=note.start,end=note.end,pitch=note.pitch,velocity=90))
    out.dump(path)
def to_notes(piano_roll):
    pad_size=len(piano_roll)
    padded_pianoroll=piano_roll.T
    padded_pianoroll=np.vstack((np.zeros((24,pad_size)),padded_pianoroll,np.zeros((20,pad_size)))).T
    notes_from_pianoroll = pr_parser.pianoroll2notes(padded_pianoroll)
    return notes_from_pianoroll

# example = np.array(piano[100:108])
# example2 = np.array(orchestra[100:108])
# example=example.reshape((-1,84))
# example2 = example2.reshape((-1,84))
# write_midi(to_notes(example),path="paired_piano.mid")
# write_midi(to_notes(example2),path="paired_orchestra.mid")


# In[ ]:


random_vector = tf.random.normal(shape=(128, random_vector_size))


# In[ ]:


a=test.generator([piano[:128],random_vector])


# In[ ]:


res = test.discriminator([tf.reshape(piano[:128], (-1,1,96,84,1)),
                    tf.reshape(a, (-1,1,96,84,1))])


# In[ ]:


for row in a[0]:
    for cell in row:
        print(int(cell),end=' ')
    print()


# In[ ]:


a[0]


# In[23]:


#Case study
o_ex = orchestra[200:208]
p_ex = piano[200:208]
p_ex = p_ex.reshape((-1,96,84))
random_vector = tf.random.normal(shape=(len(p_ex), random_vector_size))
p2o = loaded_model.predict([p_ex,random_vector])
p2o_check_discriminator_output = p2o.reshape((-1,1,96,84,1))
pex_check_discriminator_output = p_ex.reshape((-1,1,96,84,1))
oex_check_discriminator_output = o_ex.reshape((-1,1,96,84,1))
check = test.discriminator.predict([pex_check_discriminator_output,p2o_check_discriminator_output])
print(check)
check2 = test.discriminator.predict([pex_check_discriminator_output,oex_check_discriminator_output])
print(check2)
print(p2o.shape)
o_ex = o_ex.reshape((-1,84))
p_ex = p_ex.reshape((-1,84))
p2o = p2o.reshape((-1,84))
p2o = (p2o>0.5)*1
write_midi(to_notes(o_ex),path="paired_piano.mid")
write_midi(to_notes(p_ex),path="paired_orchestra.mid")
write_midi(to_notes(p2o),path="paired_p2o.mid")


# In[20]:


loaded_model = tf.keras.models.load_model('pretrain1_gen')

loaded_model.


# In[18]:


test.generator.save("pretrain1_gen")
test.discriminator.save("pretrain1_dis")

