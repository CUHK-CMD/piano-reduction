{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "K_bar = 1\n",
    "num_generated_channel = 1\n",
    "batch_size = 32\n",
    "skip_connections = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 96, 84, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 96, 7, 16)    208         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 96, 7, 16)    64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 96, 1, 16)    1808        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 96, 1, 16)    64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 1, 16)    784         batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 1, 16)    64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 1, 16)    528         batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 1, 16)    64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 1, 16)     528         batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 1, 16)     64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 1, 16)     528         batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 1, 16)     64          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 4, 1, 16)     0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 8, 1, 16)     528         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 1, 16)     64          conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 1, 16)     0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 16, 1, 16)    528         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 1, 16)    64          conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 1, 16)    0           batch_normalization_19[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 32, 1, 16)    528         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 1, 16)    64          conv2d_transpose_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 1, 16)    0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 96, 1, 16)    784         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 96, 1, 16)    64          conv2d_transpose_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 96, 1, 16)    0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 96, 7, 16)    1808        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 96, 7, 16)    64          conv2d_transpose_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 96, 7, 16)    0           batch_normalization_22[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 96, 84, 1)    193         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 96, 84, 1)    4           conv2d_transpose_11[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 9,461\n",
      "Trainable params: 9,107\n",
      "Non-trainable params: 354\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#ENCODER\n",
    "encoder_input = tf.keras.Input(shape=(96,84,1))\n",
    "encoder_pitchconv1 = tf.keras.layers.Conv2D(16,(1,12),(1,12),activation=LeakyReLU())(encoder_input)\n",
    "encoder_bn1 = tf.keras.layers.BatchNormalization()(encoder_pitchconv1)\n",
    "encoder_pitchconv2 = tf.keras.layers.Conv2D(16,(1,7),(1,7),activation=LeakyReLU())(encoder_bn1)\n",
    "encoder_bn2 = tf.keras.layers.BatchNormalization()(encoder_pitchconv2)\n",
    "encoder_timeconv1 = tf.keras.layers.Conv2D(16,(3,1),(3,1),activation=LeakyReLU())(encoder_bn2)\n",
    "encoder_bn3 = tf.keras.layers.BatchNormalization()(encoder_timeconv1)\n",
    "encoder_timeconv2 = tf.keras.layers.Conv2D(16,(2,1),(2,1),activation=LeakyReLU())(encoder_bn3)\n",
    "encoder_bn4 = tf.keras.layers.BatchNormalization()(encoder_timeconv2)\n",
    "encoder_timeconv3 = tf.keras.layers.Conv2D(16,(2,1),(2,1),activation=LeakyReLU())(encoder_bn4)\n",
    "encoder_bn5 = tf.keras.layers.BatchNormalization()(encoder_timeconv3)\n",
    "encoder_timeconv4 = tf.keras.layers.Conv2D(16,(2,1),(2,1),activation=LeakyReLU())(encoder_bn5)\n",
    "encoder_bn6 = tf.keras.layers.BatchNormalization()(encoder_timeconv4)\n",
    "encoder_output = tf.keras.layers.Flatten()(encoder_bn6)\n",
    "\n",
    "decoder_input = tf.keras.layers.Reshape((4,1,16))(encoder_output)\n",
    "decoder_timeconv1 = tf.keras.layers.Conv2DTranspose(16,(2,1),(2,1),activation=LeakyReLU())(decoder_input)\n",
    "decoder_bn1 = tf.keras.layers.BatchNormalization()(decoder_timeconv1)\n",
    "decoder_out1 = tf.keras.layers.add([decoder_bn1,encoder_bn5])\n",
    "decoder_timeconv2 = tf.keras.layers.Conv2DTranspose(16,(2,1),(2,1),activation=LeakyReLU())(decoder_out1)\n",
    "decoder_bn2 = tf.keras.layers.BatchNormalization()(decoder_timeconv2)\n",
    "decoder_out2 = tf.keras.layers.add([decoder_bn2,encoder_bn4])\n",
    "decoder_timeconv3 = tf.keras.layers.Conv2DTranspose(16,(2,1),(2,1),activation=LeakyReLU())(decoder_out2)\n",
    "decoder_bn3 = tf.keras.layers.BatchNormalization()(decoder_timeconv3)\n",
    "decoder_out3 = tf.keras.layers.add([decoder_bn3,encoder_bn3])\n",
    "decoder_timeconv4 = tf.keras.layers.Conv2DTranspose(16,(3,1),(3,1),activation=LeakyReLU())(decoder_out3)\n",
    "decoder_bn4 = tf.keras.layers.BatchNormalization()(decoder_timeconv4)\n",
    "decoder_out4 = tf.keras.layers.add([decoder_bn4,encoder_bn2])\n",
    "decoder_pitchconv1 = tf.keras.layers.Conv2DTranspose(16,(1,7),(1,7),activation=LeakyReLU())(decoder_out4)\n",
    "decoder_bn5 = tf.keras.layers.BatchNormalization()(decoder_pitchconv1)\n",
    "decoder_out5 = tf.keras.layers.add([decoder_bn5,encoder_bn1])\n",
    "decoder_pitchconv2 = tf.keras.layers.Conv2DTranspose(1,(1,12),(1,12),activation='sigmoid')(decoder_out5)\n",
    "decoder_output = tf.keras.layers.BatchNormalization()(decoder_pitchconv2)\n",
    "\n",
    "\n",
    "autoencoder= tf.keras.Model(encoder_input,decoder_output,name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 96, 84, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 96, 7, 16)         208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 96, 7, 16)         64        \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 96, 1, 16)         1808      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 96, 1, 16)         64        \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 1, 16)         784       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32, 1, 16)         64        \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 1, 16)         528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 16, 1, 16)         64        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 1, 16)          528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 8, 1, 16)          64        \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 1, 16)          528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 4, 1, 16)          64        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 4,768\n",
      "Trainable params: 4,576\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = tf.keras.Model(encoder_input,encoder_output,name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we update G once every five updates of D and apply batch normalization only to G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For the Autoencoder, train one version on piano and one version on orchestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. implement skip connections\n",
    "#2. build also the generateor and discriminator based on pix2pix version as well"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79984e8afee504c2708d2d2c681bfebf477836cea832dbf04e0f4e1cb9b885d1"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('fyp36')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
