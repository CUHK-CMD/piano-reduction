{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use Python 3 (ipykernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "K_bar = 1 #Number of tracks generated by the generator\n",
    "num_sequential_bars = 1 #For discriminator\n",
    "num_tracks = 1 #For discriminator\n",
    "batch_size = 64\n",
    "skip_connections = True\n",
    "random_vector_size=16\n",
    "discriminator_extra_steps = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 96, 84, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 96, 7, 16)    208         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 96, 7, 16)    64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 96, 1, 16)    1808        batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 96, 1, 16)    64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 1, 16)    1552        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 1, 16)    64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 1, 8)      520         batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 1, 8)      32          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 2, 1, 8)      136         batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 2, 1, 8)      32          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16)           0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 2, 1, 8)      0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 4, 1, 8)      136         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 1, 8)      32          conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 4, 1, 8)      0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 16, 1, 16)    528         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 1, 16)    64          conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 1, 16)    0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 96, 1, 16)    1552        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 96, 1, 16)    64          conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 96, 7, 16)    1808        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 96, 7, 16)    64          conv2d_transpose_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 96, 84, 1)    193         batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 8,921\n",
      "Trainable params: 8,681\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load trained autoencoder\n",
    "from tensorflow.keras.models import load_model\n",
    "trained_autoencoder = load_model('NEWpiano_encoder-loss0.03.hdf5', custom_objects={'LeakyReLU': LeakyReLU})\n",
    "trained_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN generator structure\n",
    "\n",
    "# pretrained encoder\n",
    "pretrained_encoder_input = trained_autoencoder.input\n",
    "pretrained_encoder_output = trained_autoencoder.get_layer(index=11).output\n",
    "skip1_output = trained_autoencoder.get_layer(index=8).output\n",
    "skip2_output = trained_autoencoder.get_layer(index=6).output\n",
    "pretrained_encoder = tf.keras.Model(pretrained_encoder_input,pretrained_encoder_output,name='pretrained_encoder')\n",
    "#Thomas: try to freeze the encoder training first, to stabilize training \n",
    "pretrained_encoder.trainable = False #TRUE NOW\n",
    "\n",
    "# generator\n",
    "generator_input = tf.keras.Input((1,1,16+random_vector_size), name='gen_input')\n",
    "skip1_input = tf.keras.Input((4,1,8), name='skip1_input')\n",
    "skip2_input = tf.keras.Input((16,1,16), name='skip2_input')\n",
    "x = tf.keras.layers.Conv2DTranspose(1024,(2,1),(2,1),activation=\"relu\")(generator_input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(256,(2,1),(2,1),activation=\"relu\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.concatenate([x,skip1_input])\n",
    "x = tf.keras.layers.Conv2DTranspose(256,(2,1),(2,1),activation=\"relu\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(256,(2,1),(2,1),activation=\"relu\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.concatenate([x,skip2_input])\n",
    "x = tf.keras.layers.Conv2DTranspose(128,(2,1),(2,1),activation=\"relu\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(128,(3,1),(3,1),activation=\"relu\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(64,(1,7),(1,7),activation=\"relu\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(K_bar,(1,12),(1,12),activation=\"sigmoid\")(x)\n",
    "generator_output = tf.keras.layers.BatchNormalization()(x)\n",
    "generator = tf.keras.Model([generator_input,skip1_input,skip2_input],generator_output,name='generator')\n",
    "\n",
    "\n",
    "#random vector\n",
    "random_vector_input = tf.keras.Input((random_vector_size))\n",
    "\n",
    "#concatenate\n",
    "random_and_latent = tf.keras.layers.concatenate([pretrained_encoder.output, random_vector_input],axis=-1)\n",
    "random_and_latent = tf.keras.layers.Reshape((1,1,16+random_vector_size))(random_and_latent)\n",
    "\n",
    "#generator\n",
    "gan = generator([random_and_latent,skip1_output,skip2_output])\n",
    "\n",
    "gan_generator = tf.keras.Model([pretrained_encoder_input, random_vector_input],gan,name='gan_generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator: 1: Fake, 0: Real\n",
    "discriminator_paired_input1 = tf.keras.Input((num_sequential_bars,96,84,num_tracks))\n",
    "discriminator_paired_input2 = tf.keras.Input((num_sequential_bars,96,84,num_tracks))\n",
    "x = tf.keras.layers.concatenate([discriminator_paired_input1,discriminator_paired_input2])\n",
    "x = tf.keras.layers.Conv3D(128,(1,1,1),(1,1,1),activation=LeakyReLU())(x)\n",
    "x = tf.keras.layers.Conv3D(128,(1,1,1),(1,1,1),activation=LeakyReLU())(x)\n",
    "x = tf.keras.layers.Conv3D(128,(1,1,12),(1,1,12),activation=LeakyReLU())(x)\n",
    "x = tf.keras.layers.Conv3D(128,(1,1,7),(1,1,7),activation=LeakyReLU())(x)\n",
    "x = tf.keras.layers.Conv3D(128,(1,2,1),(1,2,1),activation=LeakyReLU())(x)\n",
    "x = tf.keras.layers.Conv3D(128,(1,2,1),(1,2,1),activation=LeakyReLU())(x)\n",
    "x = tf.keras.layers.Conv3D(256,(1,4,1),(1,4,1),activation=LeakyReLU())(x)\n",
    "x = tf.keras.layers.Conv3D(512,(1,3,1),(1,2,1),activation=LeakyReLU())(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "#Thomas: CHange this to linear (from sigmoid)\n",
    "discriminator_output = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "discriminator_paired = tf.keras.Model([discriminator_paired_input1,discriminator_paired_input2],discriminator_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gan_generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 96, 84, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 96, 7, 16)    208         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 96, 7, 16)    64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 96, 1, 16)    1808        batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 96, 1, 16)    64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 1, 16)    1552        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 1, 16)    64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 1, 8)      520         batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 1, 8)      32          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 2, 1, 8)      136         batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 2, 1, 8)      32          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16)           0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 32)           0           flatten_1[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 32)     0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "generator (Functional)          (None, 96, 84, 1)    1043525     reshape_2[0][0]                  \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,048,005\n",
      "Trainable params: 1,039,299\n",
      "Non-trainable params: 8,706\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "gen_input (InputLayer)          [(None, 1, 1, 32)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_58 (Conv2DTran (None, 2, 1, 1024)   66560       gen_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 2, 1, 1024)   4096        conv2d_transpose_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_59 (Conv2DTran (None, 4, 1, 256)    524544      batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 4, 1, 256)    1024        conv2d_transpose_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "skip1_input (InputLayer)        [(None, 4, 1, 8)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 4, 1, 264)    0           batch_normalization_59[0][0]     \n",
      "                                                                 skip1_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_60 (Conv2DTran (None, 8, 1, 256)    135424      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 1, 256)    1024        conv2d_transpose_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_61 (Conv2DTran (None, 16, 1, 256)   131328      batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 16, 1, 256)   1024        conv2d_transpose_61[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "skip2_input (InputLayer)        [(None, 16, 1, 16)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 1, 272)   0           batch_normalization_61[0][0]     \n",
      "                                                                 skip2_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_62 (Conv2DTran (None, 32, 1, 128)   69760       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 1, 128)   512         conv2d_transpose_62[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_63 (Conv2DTran (None, 96, 1, 128)   49280       batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 96, 1, 128)   512         conv2d_transpose_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_64 (Conv2DTran (None, 96, 7, 64)    57408       batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 96, 7, 64)    256         conv2d_transpose_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_65 (Conv2DTran (None, 96, 84, 1)    769         batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 96, 84, 1)    4           conv2d_transpose_65[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,043,525\n",
      "Trainable params: 1,039,299\n",
      "Non-trainable params: 4,226\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 96, 84, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1, 96, 84, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 96, 84, 2) 0           input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 1, 96, 84, 12 384         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 1, 96, 84, 12 16512       conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 1, 96, 7, 128 196736      conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 1, 96, 1, 128 114816      conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 1, 48, 1, 128 32896       conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 1, 24, 1, 128 32896       conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 1, 6, 1, 256) 131328      conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 1, 2, 1, 512) 393728      conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1025        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 920,321\n",
      "Trainable params: 920,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_paired.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#piano to orchestra\n",
    "#Thomas: WGAN-GP https://keras.io/examples/generative/wgan_gp/\n",
    "class GAN_p2o(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator,discriminator_extra_steps,gp_weight=10):\n",
    "        super(GAN_p2o, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.d_steps = discriminator_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "        self.generator_loss_tracker = tf.keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.discriminator_loss_tracker = tf.keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.generator_loss_tracker, self.discriminator_loss_tracker]\n",
    "    \n",
    "    def compile(self, discriminator_optimizer, generator_optimizer, d_loss_fn,g_loss_fn):\n",
    "        super(GAN_p2o, self).compile()\n",
    "        self.d_optimizer = discriminator_optimizer\n",
    "        self.g_optimizer = generator_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "        \n",
    "    def gradient_penalty(self, batch_size, real_piano, real_orchestra,fake_orchestra):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1,1,1,1], 0.0, 1.0)\n",
    "        diff = fake_orchestra - real_orchestra\n",
    "        interpolated = real_orchestra + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator([real_piano,interpolated], training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # input Assumption (not verified yet)\n",
    "        # piano_x: Shape(96,84,1), a bar of paried piano score\n",
    "        # (Removed) random_vector: Shape(16), a random vector sampled from Normal(0,1)\n",
    "        # orchestra_y: Shape(96,84,1), a bar of paired orchestra score\n",
    "        piano_x, orchestra_y = data\n",
    "        batch_size = tf.shape(piano_x)[0]\n",
    "        #train discriminator\n",
    "        for i in range(self.d_steps):\n",
    "            random_vector = tf.random.normal(shape=(batch_size, random_vector_size))\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_orchestra = self.generator([piano_x,random_vector])\n",
    "                fake_orchestra = tf.reshape(fake_orchestra, (-1,1,96,84,1))\n",
    "                real_orchestra = tf.reshape(orchestra_y, (-1,1,96,84,1))\n",
    "                piano_input = tf.reshape(piano_x, (-1,1,96,84,1)) \n",
    "                fake_prediction = self.discriminator([piano_input,fake_orchestra])\n",
    "                real_prediction = self.discriminator([piano_input,real_orchestra])\n",
    "                d_cost = self.d_loss_fn(real_prediction,fake_prediction)\n",
    "                gp = self.gradient_penalty(batch_size,piano_input,real_orchestra,fake_orchestra)\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "            d_gradient= tape.gradient(d_loss,self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(zip(d_gradient, self.discriminator.trainable_weights))\n",
    "            \n",
    "        #train generator\n",
    "        random_vector = tf.random.normal(shape=(batch_size, random_vector_size))\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_orchestra = self.generator([piano_x,random_vector])\n",
    "            fake_orchestra = tf.reshape(fake_orchestra, (-1,1,96,84,1))\n",
    "            piano_input = tf.reshape(piano_x, (-1,1,96,84,1)) \n",
    "            discriminator_pred = self.discriminator([piano_input,fake_orchestra])\n",
    "            g_loss = self.g_loss_fn(discriminator_pred)\n",
    "        #calculate generator gradient\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        #update generator weight        \n",
    "        self.g_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_weights))\n",
    "        \n",
    "        #Loss\n",
    "        self.generator_loss_tracker.update_state(g_loss)\n",
    "        self.discriminator_loss_tracker.update_state(d_loss)\n",
    "        return{\"generator_loss\": self.generator_loss_tracker.result(),\n",
    "               \"discriminator_loss\": self.discriminator_loss_tracker.result()}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = GAN_p2o(discriminator_paired, gan_generator,discriminator_extra_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_img, fake_img):\n",
    "    #basically real = -1, fake = 1 here, using lienar function with reduce_mean to avoid optimizing to a certain value\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)\n",
    "\n",
    "\n",
    "test.compile(tf.keras.optimizers.Adam(learning_rate=0.0003), #discriminator\n",
    "             tf.keras.optimizers.Adam(learning_rate=0.0003), #generator\n",
    "             discriminator_loss, #ORiginal : CrossEntropy\n",
    "             generator_loss\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING STAGE\n",
    "1. Train two autoencoders on orchestra and piano samples respectively.\n",
    "2. Pre-train Generators with pretrain_discriminator, on orchestra and piano repsectively (pix2pix approach)\n",
    "3. Train on unpaired with Cycle-GAN approach #we update G once every five updates of D and apply batch normalization only to G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "with open(\"paired.pickle\",\"rb\") as f:\n",
    "    paired_data = pickle.load(f)\n",
    "print(len(paired_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestra=[]\n",
    "piano=[]\n",
    "for piece in paired_data:\n",
    "    for segment in piece['o']:\n",
    "        for bar in segment:\n",
    "            if bar is not None:\n",
    "                orchestra.append(bar)\n",
    "    for segment in piece['p']:\n",
    "        for bar in segment:\n",
    "            if bar is not None:\n",
    "                piano.append(bar)\n",
    "orchestra=np.array(orchestra).astype('float32')\n",
    "piano=np.array(piano).astype('float32')\n",
    "assert(orchestra.shape == piano.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(piano.shape == orchestra.shape)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((piano, orchestra))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch > 0:\n",
    "            test.generator.save(f\"pretrain1_gen{epoch}\")\n",
    "            test.discriminator.save(f\"pretrain1_dis{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "319/319 - 213s - generator_loss: -2.7950e+01 - discriminator_loss: -1.8208e+01\n",
      "Epoch 2/2\n",
      "319/319 - 219s - generator_loss: -2.6119e+01 - discriminator_loss: -1.8305e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_9_layer_call_and_return_conditional_losses, leaky_re_lu_9_layer_call_fn, leaky_re_lu_10_layer_call_and_return_conditional_losses, leaky_re_lu_10_layer_call_fn, leaky_re_lu_11_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as leaky_re_lu_9_layer_call_and_return_conditional_losses, leaky_re_lu_9_layer_call_fn, leaky_re_lu_10_layer_call_and_return_conditional_losses, leaky_re_lu_10_layer_call_fn, leaky_re_lu_11_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pretrain1_gen1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pretrain1_gen1/assets\n",
      "WARNING:absl:Found untraced functions such as leaky_re_lu_layer_call_and_return_conditional_losses, leaky_re_lu_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses, leaky_re_lu_1_layer_call_fn, leaky_re_lu_2_layer_call_and_return_conditional_losses while saving (showing 5 of 40). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as leaky_re_lu_layer_call_and_return_conditional_losses, leaky_re_lu_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses, leaky_re_lu_1_layer_call_fn, leaky_re_lu_2_layer_call_and_return_conditional_losses while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pretrain1_dis1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pretrain1_dis1/assets\n"
     ]
    }
   ],
   "source": [
    "history = test.fit(dataset, epochs=2,verbose=2,callbacks=[CustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some visualization\n",
    "from miditoolkit.pianoroll import parser as pr_parser\n",
    "from miditoolkit.midi import parser as mid_parser\n",
    "from miditoolkit.midi import containers as ct\n",
    "def write_midi(notes,path='out.mid',tick_per_beat=24):\n",
    "    out = mid_parser.MidiFile()\n",
    "    out.ticks_per_beat = tick_per_beat\n",
    "    out.instruments = [ct.Instrument(program=0,is_drum=False,name='post-processed piano')]\n",
    "    for note in notes:\n",
    "        assert(note.velocity)\n",
    "        out.instruments[0].notes.append(ct.Note(start=note.start,end=note.end,pitch=note.pitch,velocity=90))\n",
    "    out.dump(path)\n",
    "def to_notes(piano_roll):\n",
    "    pad_size=len(piano_roll)\n",
    "    padded_pianoroll=piano_roll.T\n",
    "    padded_pianoroll=np.vstack((np.zeros((24,pad_size)),padded_pianoroll,np.zeros((20,pad_size)))).T\n",
    "    notes_from_pianoroll = pr_parser.pianoroll2notes(padded_pianoroll)\n",
    "    return notes_from_pianoroll\n",
    "\n",
    "# example = np.array(piano[100:108])\n",
    "# example2 = np.array(orchestra[100:108])\n",
    "# example=example.reshape((-1,84))\n",
    "# example2 = example2.reshape((-1,84))\n",
    "# write_midi(to_notes(example),path=\"paired_piano.mid\")\n",
    "# write_midi(to_notes(example2),path=\"paired_orchestra.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vector = tf.random.normal(shape=(128, random_vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=test.generator([piano[:128],random_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test.discriminator([tf.reshape(piano[:128], (-1,1,96,84,1)),\n",
    "                    tf.reshape(a, (-1,1,96,84,1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in a[0]:\n",
    "    for cell in row:\n",
    "        print(int(cell),end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48.758144]\n",
      " [35.054867]\n",
      " [27.918   ]\n",
      " [47.79288 ]\n",
      " [49.371353]\n",
      " [42.92134 ]\n",
      " [41.624752]\n",
      " [36.90058 ]]\n",
      "[[67.96299 ]\n",
      " [62.325516]\n",
      " [59.194748]\n",
      " [59.89305 ]\n",
      " [78.7828  ]\n",
      " [65.86717 ]\n",
      " [68.41563 ]\n",
      " [61.9779  ]]\n",
      "(8, 96, 84, 1)\n",
      "paired_piano.mid\n",
      "paired_orchestra.mid\n",
      "paired_p2o.mid\n"
     ]
    }
   ],
   "source": [
    "#Case study\n",
    "o_ex = orchestra[200:208]\n",
    "p_ex = piano[200:208]\n",
    "p_ex = p_ex.reshape((-1,96,84))\n",
    "random_vector = tf.random.normal(shape=(len(p_ex), random_vector_size))\n",
    "p2o = loaded_model.predict([p_ex,random_vector])\n",
    "p2o_check_discriminator_output = p2o.reshape((-1,1,96,84,1))\n",
    "pex_check_discriminator_output = p_ex.reshape((-1,1,96,84,1))\n",
    "oex_check_discriminator_output = o_ex.reshape((-1,1,96,84,1))\n",
    "check = test.discriminator.predict([pex_check_discriminator_output,p2o_check_discriminator_output])\n",
    "print(check)\n",
    "check2 = test.discriminator.predict([pex_check_discriminator_output,oex_check_discriminator_output])\n",
    "print(check2)\n",
    "print(p2o.shape)\n",
    "o_ex = o_ex.reshape((-1,84))\n",
    "p_ex = p_ex.reshape((-1,84))\n",
    "p2o = p2o.reshape((-1,84))\n",
    "p2o = (p2o>0.5)*1\n",
    "write_midi(to_notes(o_ex),path=\"paired_piano.mid\")\n",
    "write_midi(to_notes(p_ex),path=\"paired_orchestra.mid\")\n",
    "write_midi(to_notes(p2o),path=\"paired_p2o.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"gan_generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 96, 84, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 96, 7, 16)    208         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 96, 7, 16)    64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 96, 1, 16)    1808        batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 96, 1, 16)    64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 1, 16)    1552        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 1, 16)    64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 1, 8)      520         batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 1, 8)      32          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 2, 1, 8)      136         batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 2, 1, 8)      32          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16)           0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32)           0           flatten_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1, 32)     0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "generator (Functional)          (None, 96, 84, 1)    1043525     reshape[0][0]                    \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,048,005\n",
      "Trainable params: 1,039,299\n",
      "Non-trainable params: 8,706\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 96, 84, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1, 96, 84, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 96, 84, 2) 0           input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 1, 96, 84, 12 384         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 1, 96, 84, 12 16512       conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 1, 96, 7, 128 196736      conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 1, 96, 1, 128 114816      conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 1, 48, 1, 128 32896       conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 1, 24, 1, 128 32896       conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 1, 6, 1, 256) 131328      conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 1, 2, 1, 512) 393728      conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1025        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 920,321\n",
      "Trainable params: 920,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check training results of o2p\n",
    "import tensorflow as tf\n",
    "trained_gen = tf.keras.models.load_model('pretrain2_o2p_gen90.h5', custom_objects={'LeakyReLU': LeakyReLU})\n",
    "trained_dis = tf.keras.models.load_model('pretrain2_o2p_dis90.h5', custom_objects={'LeakyReLU': LeakyReLU})\n",
    "trained_gen.summary()\n",
    "trained_dis.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-163.80586]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_0.mid\n",
      "[[-163.74603]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_1.mid\n",
      "[[-163.69057]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_2.mid\n",
      "[[-163.70187]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_3.mid\n",
      "[[-163.92581]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_4.mid\n",
      "[[-164.03137]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_5.mid\n",
      "[[-163.878  ]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_6.mid\n",
      "[[-163.84651]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_7.mid\n",
      "[[-164.1795 ]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_8.mid\n",
      "[[-164.08951]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_9.mid\n",
      "[[-164.11023]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_10.mid\n",
      "[[-163.95627]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_11.mid\n",
      "[[-164.0437 ]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_12.mid\n",
      "[[-163.72147]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_13.mid\n",
      "[[-163.75616]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_14.mid\n",
      "[[-164.11435]\n",
      " [-196.06877]\n",
      " [-227.19725]\n",
      " [-159.2756 ]\n",
      " [-190.45132]\n",
      " [-213.0126 ]\n",
      " [-131.37949]\n",
      " [-204.15167]]\n",
      "[[-148.05322]\n",
      " [-179.98708]\n",
      " [-209.81982]\n",
      " [-151.40926]\n",
      " [-181.1845 ]\n",
      " [-210.33598]\n",
      " [-119.08073]\n",
      " [-185.11209]]\n",
      "(8, 96, 84, 1)\n",
      "paired_o2p_15.mid\n"
     ]
    }
   ],
   "source": [
    "#Case study\n",
    "for i in range(16):\n",
    "    o_ex = piano[300:308]\n",
    "    p_ex = orchestra[300:308]\n",
    "    p_ex = p_ex.reshape((-1,96,84))\n",
    "    random_vector = np.zeros(shape=(len(p_ex), random_vector_size))\n",
    "    random_vector[0][i] = 1\n",
    "    p2o = trained_gen.predict([p_ex,random_vector])\n",
    "    p2o_check_discriminator_output = p2o.reshape((-1,1,96,84,1))\n",
    "    pex_check_discriminator_output = p_ex.reshape((-1,1,96,84,1))\n",
    "    oex_check_discriminator_output = o_ex.reshape((-1,1,96,84,1))\n",
    "    check = trained_dis.predict([pex_check_discriminator_output,p2o_check_discriminator_output])\n",
    "    print(check)\n",
    "    check2 = trained_dis.predict([pex_check_discriminator_output,oex_check_discriminator_output])\n",
    "    print(check2)\n",
    "    print(p2o.shape)\n",
    "    o_ex = o_ex.reshape((-1,84))\n",
    "    p_ex = p_ex.reshape((-1,84))\n",
    "    p2o = p2o.reshape((-1,84))\n",
    "    p2o = (p2o>0.5)*1\n",
    "    write_midi(to_notes(p2o),path=f\"paired_o2p_{i}.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-41.441525]\n",
      " [-46.31271 ]\n",
      " [-48.334732]\n",
      " [-49.571663]\n",
      " [-46.0318  ]\n",
      " [-66.91684 ]\n",
      " [-66.13374 ]\n",
      " [-64.79772 ]]\n",
      "[[-40.534096]\n",
      " [-37.26453 ]\n",
      " [-41.845974]\n",
      " [-40.43189 ]\n",
      " [-40.56807 ]\n",
      " [-65.78998 ]\n",
      " [-67.076416]\n",
      " [-62.728607]]\n",
      "(8, 96, 84, 1)\n"
     ]
    }
   ],
   "source": [
    "#Case study\n",
    "o_ex = orchestra[300:308]\n",
    "p_ex = piano[300:308]\n",
    "p_ex = p_ex.reshape((-1,96,84))\n",
    "random_vector = tf.random.normal(shape=(len(p_ex), random_vector_size))\n",
    "p2o = trained_gen.predict([p_ex,random_vector])\n",
    "p2o_check_discriminator_output = p2o.reshape((-1,1,96,84,1))\n",
    "pex_check_discriminator_output = p_ex.reshape((-1,1,96,84,1))\n",
    "oex_check_discriminator_output = o_ex.reshape((-1,1,96,84,1))\n",
    "check = trained_dis.predict([pex_check_discriminator_output,p2o_check_discriminator_output])\n",
    "print(check)\n",
    "check2 = trained_dis.predict([pex_check_discriminator_output,oex_check_discriminator_output])\n",
    "print(check2)\n",
    "print(p2o.shape)\n",
    "o_ex = o_ex.reshape((-1,84))\n",
    "p_ex = p_ex.reshape((-1,84))\n",
    "p2o = p2o.reshape((-1,84))\n",
    "p2o = (p2o>0.5)*1\n",
    "write_midi(to_notes(p2o),path=f\"paired_o2p_sample.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generator_loss': [17.13387680053711,\n",
       "  -41.89957809448242,\n",
       "  3.934168577194214,\n",
       "  23.50783348083496,\n",
       "  24.656169891357422,\n",
       "  20.239099502563477,\n",
       "  13.699612617492676,\n",
       "  17.90256118774414,\n",
       "  16.671100616455078,\n",
       "  19.425386428833008,\n",
       "  8.569153785705566,\n",
       "  3.4579386711120605,\n",
       "  -2.49971342086792,\n",
       "  -0.5727148056030273,\n",
       "  -3.894751787185669,\n",
       "  -6.869997978210449,\n",
       "  -2.197458505630493,\n",
       "  -2.874846935272217,\n",
       "  -6.306809902191162,\n",
       "  -7.884347438812256,\n",
       "  -12.19917106628418,\n",
       "  -16.15288543701172,\n",
       "  -14.2255859375,\n",
       "  -14.429638862609863,\n",
       "  -15.355735778808594,\n",
       "  -13.154736518859863,\n",
       "  -8.6796875,\n",
       "  -11.414508819580078,\n",
       "  -12.76332950592041,\n",
       "  -13.600305557250977,\n",
       "  -15.117698669433594,\n",
       "  -12.79772663116455,\n",
       "  -19.91156768798828,\n",
       "  -17.870363235473633,\n",
       "  -18.438575744628906,\n",
       "  -24.84276580810547,\n",
       "  -22.19681167602539,\n",
       "  -24.492786407470703,\n",
       "  -19.560192108154297,\n",
       "  -18.847644805908203,\n",
       "  -23.765026092529297,\n",
       "  -23.058881759643555,\n",
       "  -22.76059913635254,\n",
       "  -24.253276824951172,\n",
       "  -26.8271484375,\n",
       "  -28.041316986083984,\n",
       "  -26.634496688842773,\n",
       "  -28.0775089263916,\n",
       "  -27.387271881103516,\n",
       "  -27.436203002929688,\n",
       "  -25.929519653320312,\n",
       "  -25.921173095703125,\n",
       "  -27.344589233398438,\n",
       "  -28.545602798461914,\n",
       "  -30.12813949584961,\n",
       "  -30.036773681640625,\n",
       "  -31.231693267822266,\n",
       "  -30.91695785522461,\n",
       "  -28.140792846679688,\n",
       "  -26.594303131103516,\n",
       "  -26.852542877197266,\n",
       "  -25.889352798461914,\n",
       "  -24.467153549194336,\n",
       "  -24.71004295349121,\n",
       "  -22.356775283813477,\n",
       "  -22.47058868408203,\n",
       "  -19.994783401489258,\n",
       "  -19.59958267211914,\n",
       "  -19.74038314819336,\n",
       "  -19.674625396728516,\n",
       "  -18.082584381103516,\n",
       "  -17.723127365112305,\n",
       "  -16.1503963470459,\n",
       "  -16.189191818237305,\n",
       "  -17.851469039916992,\n",
       "  -16.847902297973633,\n",
       "  -14.004226684570312,\n",
       "  -13.057220458984375,\n",
       "  -11.532098770141602,\n",
       "  -11.865689277648926,\n",
       "  -10.591182708740234,\n",
       "  -7.256727695465088,\n",
       "  -6.412742614746094,\n",
       "  -5.680780410766602,\n",
       "  -0.26842111349105835,\n",
       "  2.703172445297241,\n",
       "  7.472873687744141,\n",
       "  10.486035346984863,\n",
       "  13.262434005737305,\n",
       "  16.318655014038086,\n",
       "  18.829538345336914,\n",
       "  21.5445556640625,\n",
       "  23.817882537841797,\n",
       "  24.300758361816406,\n",
       "  28.14507484436035,\n",
       "  28.919530868530273,\n",
       "  32.908451080322266,\n",
       "  32.02611541748047,\n",
       "  36.534820556640625,\n",
       "  40.53388214111328,\n",
       "  41.55068588256836,\n",
       "  46.17683410644531,\n",
       "  47.463661193847656,\n",
       "  47.65673065185547,\n",
       "  51.36125564575195,\n",
       "  51.33927536010742,\n",
       "  54.09090042114258,\n",
       "  55.103736877441406,\n",
       "  59.39019775390625,\n",
       "  61.39664840698242,\n",
       "  64.2969741821289,\n",
       "  66.23762512207031,\n",
       "  69.36036682128906,\n",
       "  69.44930267333984,\n",
       "  72.13196563720703,\n",
       "  74.14082336425781,\n",
       "  71.93304443359375,\n",
       "  74.2289047241211,\n",
       "  80.3419189453125,\n",
       "  77.37782287597656,\n",
       "  77.48165130615234,\n",
       "  79.49452209472656,\n",
       "  81.92768096923828,\n",
       "  84.71797180175781,\n",
       "  85.76451110839844,\n",
       "  86.67906951904297,\n",
       "  92.92581176757812,\n",
       "  94.85420227050781,\n",
       "  94.36856079101562,\n",
       "  95.23475646972656,\n",
       "  100.6120834350586,\n",
       "  99.93830871582031,\n",
       "  104.09782409667969,\n",
       "  109.22895812988281,\n",
       "  110.32063293457031,\n",
       "  110.65750885009766,\n",
       "  116.01126861572266,\n",
       "  115.88429260253906,\n",
       "  118.77439880371094,\n",
       "  118.6723861694336,\n",
       "  120.68131256103516,\n",
       "  127.19758605957031,\n",
       "  130.07168579101562,\n",
       "  131.52064514160156,\n",
       "  135.85752868652344,\n",
       "  141.34799194335938,\n",
       "  141.8686981201172,\n",
       "  140.6988525390625,\n",
       "  141.37728881835938,\n",
       "  141.88084411621094,\n",
       "  143.16746520996094,\n",
       "  145.1014404296875,\n",
       "  147.1903076171875,\n",
       "  147.33981323242188,\n",
       "  141.8274688720703,\n",
       "  145.21939086914062,\n",
       "  143.93072509765625,\n",
       "  147.60684204101562,\n",
       "  148.74508666992188,\n",
       "  149.5998992919922,\n",
       "  152.48471069335938,\n",
       "  152.0194549560547,\n",
       "  152.5306854248047,\n",
       "  152.3368377685547,\n",
       "  152.1072540283203,\n",
       "  154.97235107421875,\n",
       "  154.23983764648438,\n",
       "  153.52589416503906,\n",
       "  157.12892150878906,\n",
       "  159.6597442626953,\n",
       "  157.32728576660156,\n",
       "  161.305419921875,\n",
       "  155.75331115722656,\n",
       "  157.02633666992188,\n",
       "  159.42880249023438,\n",
       "  161.37686157226562,\n",
       "  166.53009033203125,\n",
       "  168.09774780273438,\n",
       "  169.23672485351562,\n",
       "  172.5216522216797,\n",
       "  170.86538696289062,\n",
       "  170.08132934570312,\n",
       "  177.48414611816406,\n",
       "  181.25738525390625,\n",
       "  179.77598571777344,\n",
       "  182.85899353027344,\n",
       "  183.9771270751953,\n",
       "  181.7518310546875,\n",
       "  178.91116333007812,\n",
       "  179.45571899414062,\n",
       "  178.20120239257812,\n",
       "  179.28594970703125,\n",
       "  181.5516815185547,\n",
       "  179.84646606445312,\n",
       "  183.81967163085938,\n",
       "  183.94497680664062,\n",
       "  180.48019409179688,\n",
       "  184.39466857910156,\n",
       "  186.82179260253906,\n",
       "  189.64974975585938,\n",
       "  192.7296905517578,\n",
       "  193.9597930908203,\n",
       "  196.82888793945312,\n",
       "  201.56900024414062,\n",
       "  200.9816131591797,\n",
       "  207.7969207763672,\n",
       "  197.97262573242188,\n",
       "  202.08596801757812,\n",
       "  198.37692260742188,\n",
       "  195.25057983398438,\n",
       "  202.0713348388672,\n",
       "  200.66348266601562,\n",
       "  200.54071044921875,\n",
       "  202.28245544433594,\n",
       "  202.91305541992188,\n",
       "  202.67677307128906,\n",
       "  207.42721557617188,\n",
       "  207.59365844726562,\n",
       "  207.10018920898438,\n",
       "  205.9259796142578,\n",
       "  204.12460327148438,\n",
       "  204.8294677734375,\n",
       "  210.8206787109375,\n",
       "  214.31527709960938,\n",
       "  209.77993774414062,\n",
       "  207.0262451171875,\n",
       "  206.6736602783203,\n",
       "  213.12796020507812,\n",
       "  216.30972290039062,\n",
       "  213.6814727783203,\n",
       "  217.50247192382812,\n",
       "  205.5618896484375,\n",
       "  208.7023162841797,\n",
       "  209.5010986328125,\n",
       "  210.6290283203125,\n",
       "  209.1279754638672,\n",
       "  210.49697875976562,\n",
       "  212.8947296142578,\n",
       "  216.8578338623047,\n",
       "  212.5802001953125,\n",
       "  216.1315460205078,\n",
       "  214.88412475585938,\n",
       "  219.3307342529297,\n",
       "  215.51718139648438,\n",
       "  219.46530151367188,\n",
       "  217.7969207763672,\n",
       "  215.01052856445312,\n",
       "  215.88076782226562,\n",
       "  217.8099822998047,\n",
       "  223.14028930664062,\n",
       "  223.68264770507812,\n",
       "  224.02609252929688,\n",
       "  219.1537322998047,\n",
       "  216.47830200195312,\n",
       "  224.83761596679688,\n",
       "  230.1873016357422,\n",
       "  229.27957153320312,\n",
       "  233.04312133789062,\n",
       "  227.92410278320312,\n",
       "  224.82553100585938,\n",
       "  223.4527130126953,\n",
       "  222.51791381835938,\n",
       "  218.18569946289062,\n",
       "  222.84054565429688,\n",
       "  221.9008331298828,\n",
       "  224.4141387939453,\n",
       "  227.09994506835938,\n",
       "  219.98751831054688,\n",
       "  207.49081420898438,\n",
       "  223.7260284423828,\n",
       "  224.82528686523438,\n",
       "  221.3180389404297,\n",
       "  219.52566528320312,\n",
       "  232.27865600585938,\n",
       "  236.02456665039062,\n",
       "  238.8821563720703,\n",
       "  235.6484375,\n",
       "  228.41598510742188,\n",
       "  227.16665649414062,\n",
       "  225.5316162109375,\n",
       "  228.42910766601562,\n",
       "  226.9386749267578,\n",
       "  227.62167358398438,\n",
       "  232.81539916992188,\n",
       "  229.60427856445312,\n",
       "  231.325439453125,\n",
       "  206.4892578125,\n",
       "  224.0792999267578,\n",
       "  225.647705078125,\n",
       "  215.0758514404297,\n",
       "  233.495849609375,\n",
       "  242.07247924804688,\n",
       "  241.60781860351562,\n",
       "  243.31674194335938,\n",
       "  239.9547882080078,\n",
       "  240.2156982421875,\n",
       "  240.8943328857422,\n",
       "  235.1973876953125,\n",
       "  238.3514862060547,\n",
       "  244.21371459960938],\n",
       " 'discriminator_loss': [-36.66411590576172,\n",
       "  -31.653141021728516,\n",
       "  -34.62604522705078,\n",
       "  -35.433475494384766,\n",
       "  -36.58602523803711,\n",
       "  -35.637367248535156,\n",
       "  -35.31342315673828,\n",
       "  -35.41127014160156,\n",
       "  -35.964256286621094,\n",
       "  -34.920162200927734,\n",
       "  -34.92311096191406,\n",
       "  -34.3963508605957,\n",
       "  -33.62865447998047,\n",
       "  -33.00422286987305,\n",
       "  -33.37273025512695,\n",
       "  -32.954708099365234,\n",
       "  -32.75676727294922,\n",
       "  -32.36423110961914,\n",
       "  -31.899999618530273,\n",
       "  -31.34235191345215,\n",
       "  -30.2683048248291,\n",
       "  -30.222698211669922,\n",
       "  -29.551387786865234,\n",
       "  -29.059162139892578,\n",
       "  -29.083877563476562,\n",
       "  -28.384185791015625,\n",
       "  -28.851238250732422,\n",
       "  -27.90692710876465,\n",
       "  -27.421398162841797,\n",
       "  -28.143152236938477,\n",
       "  -27.607669830322266,\n",
       "  -26.837535858154297,\n",
       "  -26.560876846313477,\n",
       "  -26.417104721069336,\n",
       "  -26.665130615234375,\n",
       "  -26.337738037109375,\n",
       "  -26.48116683959961,\n",
       "  -25.570789337158203,\n",
       "  -25.085939407348633,\n",
       "  -24.826133728027344,\n",
       "  -24.7642879486084,\n",
       "  -24.75583267211914,\n",
       "  -24.485986709594727,\n",
       "  -24.433164596557617,\n",
       "  -24.752277374267578,\n",
       "  -24.90814208984375,\n",
       "  -24.162090301513672,\n",
       "  -23.70764923095703,\n",
       "  -24.023754119873047,\n",
       "  -23.519264221191406,\n",
       "  -23.759784698486328,\n",
       "  -23.808801651000977,\n",
       "  -23.610010147094727,\n",
       "  -23.055269241333008,\n",
       "  -23.514629364013672,\n",
       "  -23.68222427368164,\n",
       "  -23.61620330810547,\n",
       "  -23.355602264404297,\n",
       "  -22.691556930541992,\n",
       "  -22.38909912109375,\n",
       "  -22.299509048461914,\n",
       "  -22.41695213317871,\n",
       "  -22.22264289855957,\n",
       "  -22.205102920532227,\n",
       "  -21.905677795410156,\n",
       "  -21.51491928100586,\n",
       "  -21.322917938232422,\n",
       "  -21.33864402770996,\n",
       "  -21.67532730102539,\n",
       "  -21.75218391418457,\n",
       "  -21.68014907836914,\n",
       "  -21.607162475585938,\n",
       "  -21.482749938964844,\n",
       "  -21.3575382232666,\n",
       "  -21.39068031311035,\n",
       "  -21.394081115722656,\n",
       "  -21.07598304748535,\n",
       "  -21.172780990600586,\n",
       "  -21.4200496673584,\n",
       "  -21.19502830505371,\n",
       "  -21.44231414794922,\n",
       "  -21.18514633178711,\n",
       "  -21.30436897277832,\n",
       "  -20.889251708984375,\n",
       "  -20.71077537536621,\n",
       "  -20.557363510131836,\n",
       "  -20.783489227294922,\n",
       "  -19.907657623291016,\n",
       "  -20.348182678222656,\n",
       "  -19.867977142333984,\n",
       "  -19.760656356811523,\n",
       "  -20.196331024169922,\n",
       "  -19.834335327148438,\n",
       "  -19.635433197021484,\n",
       "  -19.391857147216797,\n",
       "  -19.475635528564453,\n",
       "  -19.35442543029785,\n",
       "  -19.58784294128418,\n",
       "  -19.53116226196289,\n",
       "  -19.27461814880371,\n",
       "  -19.193574905395508,\n",
       "  -18.863191604614258,\n",
       "  -19.343631744384766,\n",
       "  -19.482576370239258,\n",
       "  -19.259197235107422,\n",
       "  -19.649845123291016,\n",
       "  -19.670103073120117,\n",
       "  -19.393415451049805,\n",
       "  -19.410818099975586,\n",
       "  -19.534637451171875,\n",
       "  -19.186201095581055,\n",
       "  -19.072078704833984,\n",
       "  -19.321041107177734,\n",
       "  -19.104270935058594,\n",
       "  -19.20419692993164,\n",
       "  -19.12567901611328,\n",
       "  -18.808483123779297,\n",
       "  -18.625213623046875,\n",
       "  -18.636104583740234,\n",
       "  -18.82675552368164,\n",
       "  -18.640132904052734,\n",
       "  -18.322633743286133,\n",
       "  -18.445817947387695,\n",
       "  -18.402191162109375,\n",
       "  -18.10348129272461,\n",
       "  -18.187679290771484,\n",
       "  -18.065216064453125,\n",
       "  -17.845436096191406,\n",
       "  -17.893386840820312,\n",
       "  -17.590578079223633,\n",
       "  -17.511571884155273,\n",
       "  -17.511878967285156,\n",
       "  -17.401954650878906,\n",
       "  -17.45669937133789,\n",
       "  -17.635717391967773,\n",
       "  -17.566059112548828,\n",
       "  -17.42745590209961,\n",
       "  -17.59505271911621,\n",
       "  -17.433412551879883,\n",
       "  -17.378156661987305,\n",
       "  -17.204416275024414,\n",
       "  -17.38991928100586,\n",
       "  -17.120712280273438,\n",
       "  -17.07956314086914,\n",
       "  -16.89328384399414,\n",
       "  -16.988418579101562,\n",
       "  -17.107267379760742,\n",
       "  -17.222759246826172,\n",
       "  -17.20428466796875,\n",
       "  -16.977693557739258,\n",
       "  -16.910839080810547,\n",
       "  -16.986408233642578,\n",
       "  -16.729217529296875,\n",
       "  -16.63089942932129,\n",
       "  -16.763708114624023,\n",
       "  -16.744632720947266,\n",
       "  -16.75882911682129,\n",
       "  -16.691030502319336,\n",
       "  -16.50293731689453,\n",
       "  -16.492549896240234,\n",
       "  -16.576580047607422,\n",
       "  -16.57305908203125,\n",
       "  -16.40741729736328,\n",
       "  -16.42912483215332,\n",
       "  -16.452863693237305,\n",
       "  -16.379365921020508,\n",
       "  -16.33814811706543,\n",
       "  -16.169788360595703,\n",
       "  -15.970819473266602,\n",
       "  -16.12588119506836,\n",
       "  -16.180822372436523,\n",
       "  -15.858053207397461,\n",
       "  -15.852526664733887,\n",
       "  -15.943158149719238,\n",
       "  -15.869478225708008,\n",
       "  -15.89197063446045,\n",
       "  -15.854410171508789,\n",
       "  -15.780181884765625,\n",
       "  -15.813926696777344,\n",
       "  -15.72881031036377,\n",
       "  -15.65209674835205,\n",
       "  -15.517565727233887,\n",
       "  -15.382339477539062,\n",
       "  -15.631277084350586,\n",
       "  -15.555018424987793,\n",
       "  -15.471162796020508,\n",
       "  -15.461909294128418,\n",
       "  -15.497552871704102,\n",
       "  -15.377737045288086,\n",
       "  -15.402338027954102,\n",
       "  -15.199389457702637,\n",
       "  -15.39820384979248,\n",
       "  -15.319808959960938,\n",
       "  -15.24439811706543,\n",
       "  -15.310877799987793,\n",
       "  -15.3056058883667,\n",
       "  -15.35529899597168,\n",
       "  -15.246736526489258,\n",
       "  -15.268613815307617,\n",
       "  -15.272054672241211,\n",
       "  -15.30907917022705,\n",
       "  -15.242597579956055,\n",
       "  -15.054361343383789,\n",
       "  -15.006571769714355,\n",
       "  -15.094426155090332,\n",
       "  -15.183084487915039,\n",
       "  -15.0582275390625,\n",
       "  -14.978691101074219,\n",
       "  -14.859405517578125,\n",
       "  -14.926904678344727,\n",
       "  -14.817585945129395,\n",
       "  -14.803804397583008,\n",
       "  -14.999162673950195,\n",
       "  -14.914505004882812,\n",
       "  -14.89838695526123,\n",
       "  -14.844343185424805,\n",
       "  -14.763204574584961,\n",
       "  -14.736879348754883,\n",
       "  -14.697553634643555,\n",
       "  -14.812400817871094,\n",
       "  -14.670260429382324,\n",
       "  -14.687337875366211,\n",
       "  -14.754254341125488,\n",
       "  -14.548234939575195,\n",
       "  -14.548019409179688,\n",
       "  -14.646677017211914,\n",
       "  -14.428487777709961,\n",
       "  -14.531639099121094,\n",
       "  -14.583788871765137,\n",
       "  -14.461448669433594,\n",
       "  -14.569134712219238,\n",
       "  -14.613340377807617,\n",
       "  -14.340787887573242,\n",
       "  -14.443860054016113,\n",
       "  -14.522497177124023,\n",
       "  -14.434209823608398,\n",
       "  -14.321940422058105,\n",
       "  -14.495725631713867,\n",
       "  -14.452043533325195,\n",
       "  -14.501943588256836,\n",
       "  -14.505694389343262,\n",
       "  -14.383000373840332,\n",
       "  -14.483406066894531,\n",
       "  -14.372431755065918,\n",
       "  -14.37877082824707,\n",
       "  -14.322526931762695,\n",
       "  -14.319677352905273,\n",
       "  -14.278768539428711,\n",
       "  -14.269096374511719,\n",
       "  -14.245409965515137,\n",
       "  -14.043437004089355,\n",
       "  -14.169415473937988,\n",
       "  -14.013814926147461,\n",
       "  -13.954404830932617,\n",
       "  -14.055227279663086,\n",
       "  -14.059049606323242,\n",
       "  -14.165989875793457,\n",
       "  -14.13005542755127,\n",
       "  -13.988714218139648,\n",
       "  -14.246073722839355,\n",
       "  -14.101144790649414,\n",
       "  -14.08509635925293,\n",
       "  -13.827059745788574,\n",
       "  -14.221545219421387,\n",
       "  -14.103960990905762,\n",
       "  -14.120089530944824,\n",
       "  -14.26562786102295,\n",
       "  -13.664793014526367,\n",
       "  -13.34141731262207,\n",
       "  -13.850967407226562,\n",
       "  -13.775541305541992,\n",
       "  -13.809361457824707,\n",
       "  -13.763888359069824,\n",
       "  -13.707830429077148,\n",
       "  -13.75146198272705,\n",
       "  -13.843953132629395,\n",
       "  -13.900973320007324,\n",
       "  -13.826751708984375,\n",
       "  -13.966830253601074,\n",
       "  -13.831464767456055,\n",
       "  -13.757899284362793,\n",
       "  -13.851369857788086,\n",
       "  -13.884210586547852,\n",
       "  -13.897665023803711,\n",
       "  -13.771951675415039,\n",
       "  -13.898045539855957,\n",
       "  -12.862281799316406,\n",
       "  -13.867959976196289,\n",
       "  -13.818133354187012,\n",
       "  -13.103010177612305,\n",
       "  -13.716850280761719,\n",
       "  -13.63793659210205,\n",
       "  -13.732019424438477,\n",
       "  -13.78117561340332,\n",
       "  -13.534074783325195,\n",
       "  -13.589881896972656,\n",
       "  -13.604921340942383,\n",
       "  -13.631874084472656,\n",
       "  -13.597665786743164,\n",
       "  -13.498476028442383]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"train_history_o2p.pickle\",\"rb\") as f:\n",
    "    losses = pickle.load(f)\n",
    "    \n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = np.array(losses['discriminator_loss'])\n",
    "loss = -loss\n",
    "# plt.plot(losses['generator_loss'])\n",
    "plt.plot(loss)\n",
    "plt.title('model critic loss')\n",
    "plt.ylabel('negative critic loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79984e8afee504c2708d2d2c681bfebf477836cea832dbf04e0f4e1cb9b885d1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
